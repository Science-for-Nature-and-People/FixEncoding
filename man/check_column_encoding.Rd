% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/check_column_encoding.R
\name{check_column_encoding}
\alias{check_column_encoding}
\title{Find data.frame/data.table invalid UTF-8 bytes in a data.frame.}
\usage{
check_column_encoding(dset, column_names = colnames(dset))
}
\arguments{
\item{dset}{A data.frame or data.table.}

\item{column_names}{Names of data.frame columns to search. Defaults to
\code{colnames(dset)}}
}
\value{
A list of columns where invalid bytes are detected. Each list element,
 which corresponds to a column, contains a character vector of unique
 observations where detection occurred.
}
\description{
\code{check_column_encoding} returns a list of \code{dset}
 observations where invalid UTF-8 or UTF-8 control bytes are detected by
 pattern matching, organized by original column name. NOTE: This function is
 intended only for use on UTF-8 systems, such as Mac OS X. If in doubt about
 your system encoding, run \code{Sys.getlocale()}.
}
\details{
Each byte utilized in pattern matching by
 \code{check_column_encoding} is either a single-byte control character in
 UTF-8 in the range 0x80 - 0x9f or the Unicode replacement character, U+FFFD.
 This function uses iconv() to replace all invalid UTF-8 bytes with U+FFFD;
 however, it does not convert control characters that may be present. I leave
 intact any control characters within the range 0x00 - 0x1f, which R does
 utilize. For example, to represent the newline character. See ?Quotes for a
 complete list of control characters. In the future, I may also convert
 control characters such as the carriage return.
}

